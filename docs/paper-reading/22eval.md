# Back to the Drawing Board: A Critical Evaluation of Poisoning Attacks on Production Federated Learning 针对生产环境联邦学习的投毒攻击的关键评估

IEEE S&P 2022的一篇文章，作者来自Google Research。原文在[这里](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9833647)。这篇文章主要对联邦学习中的投毒攻击进行了评估，发现了一些之前未被发现的问题。

## 摘要

联邦学习过程: 
- 数据所有者（称为客户端）在不共享私有训练数据的情况下协作训练一个共同的机器学习模型。在这种情况下，中央服务器（例如，服务提供商）重复收集客户端使用其本地私有数据计算的一些更新，使用聚合规则聚合客户端的更新，最后使用聚合的客户端更新来调整联合训练的模型（称为全局模型），该模型在每个FL训练轮结束时广播给一部分客户端。

- 也就是说，服务端的所有者也许并不完全占有客户端，进而无法控制从客户端上传的数据是否是安全的，这就为攻击者提供了机会。

- 而联邦学习中的投毒攻击是指，攻击者通过控制的某些客户端，称作**受损客户端**（compromised clients），上传毒化更新，以破坏全局模型的性能。

投毒攻击分类：

- 有目标的投毒攻击（targeted）: 对于分类器任务而言，攻击者的目标是使得全局模型在某些特定的类别上表现不佳，而其他类别上表现正常。

- 后门攻击（backdoor）: 攻击者的目标是在全局模型中植入后门，使得全局模型在具有某些特征/人工加入触发器的样本上表现不佳。

- 无目标的投毒攻击（untargeted）: 攻击者的目标是使得全局模型在整体上表现不佳。

而这篇文章集中探讨了无目标的投毒攻击，因为这种攻击与生产环境中的实际情况更加相关，能对大规模的FL系统造成更大的破坏，且更难以被察觉。

现有的投毒攻击研究:

- 数据投毒: 现阶段基本没有针对FL特化的数据投毒攻击研究，引用[23]展示了在联邦学习中进行标签翻转攻击的可能性。

- 模型投毒:

  1. Little is Enough(LIE): 攻击者计算了可用的良性更新的平均值和标准差，然后根据良性和受损客户端的数量计算了一个系数z，最后计算了毒化更新。这种噪声很容易逃避鲁棒的聚合规则的检测，同时有效地毒化了全局模型。

  2. Static Optimization (STAT-OPT): STAT-OPT计算了可用良性更新的平均值，并计算了一个静态的恶意方向，最后计算了一个毒化更新。这种攻击更加针对目标的聚合规则，因此表现更好。

  3. Dynamic Optimization (DYN-OPT):一个通用的FL投毒框架，然后根据特定的FL设置进行调整。DYN-OPT计算了可用良性更新的平均值，并在动态的、数据相关的恶意方向ω中扰动它，以计算最终的毒化更新∇′ = ∇b + γω。DYN-OPT找到了成功规避目标AGR的最大γ。DYN-OPT更强大，因为与STAT-OPT不同，它找到了最大的γ，并使用了一个定制的ω数据集。个人理解是它并不是固定的恶意扰动方向，而是根据数据集的特点进行调整，有点像梯度下降？